{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar Dataset fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train),type(y_train),type(X_test),type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('uint8'), dtype('uint8'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype,y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[0, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotar um item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 3,3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1daf67f1788>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0, :, :],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.min() ,X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000,784)\n",
    "X_test = X_test.reshape(10000,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizar e resolver compatibilidade entre python 2 e 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.astype('float32')\n",
    "X_train = X_train /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.astype('float32')\n",
    "X_test = X_test /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para o Keras precisa estar em dummy categorical a variavel de saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# units (neuronios camada escondida)\n",
    "# input_dim (atributos previsores)\n",
    "# activation='softmax'\n",
    "model = Sequential()\n",
    "# Primeira camada de neuronios\n",
    "model.add(Dense(units=100,\n",
    "                input_shape=(784,),\n",
    "                activation='relu'))\n",
    "# Segunda camada de neuronios\n",
    "model.add(Dense(units=100,\n",
    "               activation='relu'))\n",
    "# Camada de saida units=10 pq tenho 10 classes\n",
    "model.add(Dense(units=10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/128\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.9226 - accuracy: 0.6612 - val_loss: 0.6492 - val_accuracy: 0.7621\n",
      "Epoch 2/128\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.5887 - accuracy: 0.7858 - val_loss: 0.5614 - val_accuracy: 0.7998\n",
      "Epoch 3/128\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.5241 - accuracy: 0.8124 - val_loss: 0.5281 - val_accuracy: 0.8149\n",
      "Epoch 4/128\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.4821 - accuracy: 0.8275 - val_loss: 0.4979 - val_accuracy: 0.8199\n",
      "Epoch 5/128\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.4539 - accuracy: 0.8392 - val_loss: 0.4824 - val_accuracy: 0.8261\n",
      "Epoch 6/128\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.4342 - accuracy: 0.8455 - val_loss: 0.4563 - val_accuracy: 0.8332\n",
      "Epoch 7/128\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.4163 - accuracy: 0.8507 - val_loss: 0.4715 - val_accuracy: 0.8281\n",
      "Epoch 8/128\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.4026 - accuracy: 0.8559 - val_loss: 0.4455 - val_accuracy: 0.8398\n",
      "Epoch 9/128\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.3906 - accuracy: 0.8594 - val_loss: 0.4214 - val_accuracy: 0.8481\n",
      "Epoch 10/128\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.3804 - accuracy: 0.8624 - val_loss: 0.4232 - val_accuracy: 0.8485\n",
      "Epoch 11/128\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.3709 - accuracy: 0.8668 - val_loss: 0.4092 - val_accuracy: 0.8523\n",
      "Epoch 12/128\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.3622 - accuracy: 0.8683 - val_loss: 0.3998 - val_accuracy: 0.8577\n",
      "Epoch 13/128\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3541 - accuracy: 0.8710 - val_loss: 0.3995 - val_accuracy: 0.8556\n",
      "Epoch 14/128\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.3468 - accuracy: 0.8746 - val_loss: 0.3941 - val_accuracy: 0.8571\n",
      "Epoch 15/128\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.3403 - accuracy: 0.8762 - val_loss: 0.3892 - val_accuracy: 0.8595\n",
      "Epoch 16/128\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.3344 - accuracy: 0.8782 - val_loss: 0.3985 - val_accuracy: 0.8579\n",
      "Epoch 17/128\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.3296 - accuracy: 0.8790 - val_loss: 0.3815 - val_accuracy: 0.8655\n",
      "Epoch 18/128\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.3236 - accuracy: 0.8820 - val_loss: 0.3741 - val_accuracy: 0.8668\n",
      "Epoch 19/128\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.3195 - accuracy: 0.8844 - val_loss: 0.3691 - val_accuracy: 0.8696\n",
      "Epoch 20/128\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.3130 - accuracy: 0.8854 - val_loss: 0.3715 - val_accuracy: 0.8669\n",
      "Epoch 21/128\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.3106 - accuracy: 0.8863 - val_loss: 0.3649 - val_accuracy: 0.8693\n",
      "Epoch 22/128\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.3056 - accuracy: 0.8878 - val_loss: 0.3654 - val_accuracy: 0.8706\n",
      "Epoch 23/128\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3014 - accuracy: 0.8890 - val_loss: 0.3615 - val_accuracy: 0.8719\n",
      "Epoch 24/128\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2975 - accuracy: 0.8916 - val_loss: 0.3798 - val_accuracy: 0.8656\n",
      "Epoch 25/128\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.2924 - accuracy: 0.8927 - val_loss: 0.3539 - val_accuracy: 0.8747\n",
      "Epoch 26/128\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2900 - accuracy: 0.8930 - val_loss: 0.3523 - val_accuracy: 0.8758\n",
      "Epoch 27/128\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.2872 - accuracy: 0.8936 - val_loss: 0.3497 - val_accuracy: 0.8739\n",
      "Epoch 28/128\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2828 - accuracy: 0.8953 - val_loss: 0.3525 - val_accuracy: 0.8742\n",
      "Epoch 29/128\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2790 - accuracy: 0.8964 - val_loss: 0.3588 - val_accuracy: 0.8756\n",
      "Epoch 30/128\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.2763 - accuracy: 0.8975 - val_loss: 0.3671 - val_accuracy: 0.8721\n",
      "Epoch 31/128\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2735 - accuracy: 0.8983 - val_loss: 0.3491 - val_accuracy: 0.8766\n",
      "Epoch 32/128\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2708 - accuracy: 0.8987 - val_loss: 0.3458 - val_accuracy: 0.8779\n",
      "Epoch 33/128\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2663 - accuracy: 0.9011 - val_loss: 0.3524 - val_accuracy: 0.8738\n",
      "Epoch 34/128\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2644 - accuracy: 0.9017 - val_loss: 0.3566 - val_accuracy: 0.8705\n",
      "Epoch 35/128\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2609 - accuracy: 0.9026 - val_loss: 0.3615 - val_accuracy: 0.8736\n",
      "Epoch 36/128\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2582 - accuracy: 0.9035 - val_loss: 0.3439 - val_accuracy: 0.8759\n",
      "Epoch 37/128\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2554 - accuracy: 0.9042 - val_loss: 0.3366 - val_accuracy: 0.8835\n",
      "Epoch 38/128\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2527 - accuracy: 0.9056 - val_loss: 0.3448 - val_accuracy: 0.8766\n",
      "Epoch 39/128\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2506 - accuracy: 0.9061 - val_loss: 0.3360 - val_accuracy: 0.8793\n",
      "Epoch 40/128\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2478 - accuracy: 0.9085 - val_loss: 0.3510 - val_accuracy: 0.8751\n",
      "Epoch 41/128\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2457 - accuracy: 0.9086 - val_loss: 0.3390 - val_accuracy: 0.8831\n",
      "Epoch 42/128\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2429 - accuracy: 0.9099 - val_loss: 0.3412 - val_accuracy: 0.8803\n",
      "Epoch 43/128\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2414 - accuracy: 0.9106 - val_loss: 0.3421 - val_accuracy: 0.8776\n",
      "Epoch 44/128\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2376 - accuracy: 0.9113 - val_loss: 0.3345 - val_accuracy: 0.8810\n",
      "Epoch 45/128\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2351 - accuracy: 0.9127 - val_loss: 0.3435 - val_accuracy: 0.8804\n",
      "Epoch 46/128\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2334 - accuracy: 0.9123 - val_loss: 0.3387 - val_accuracy: 0.8789\n",
      "Epoch 47/128\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2313 - accuracy: 0.9137 - val_loss: 0.3295 - val_accuracy: 0.8863\n",
      "Epoch 48/128\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2281 - accuracy: 0.9165 - val_loss: 0.3385 - val_accuracy: 0.8799\n",
      "Epoch 49/128\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2268 - accuracy: 0.9151 - val_loss: 0.3356 - val_accuracy: 0.8800\n",
      "Epoch 50/128\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2244 - accuracy: 0.9169 - val_loss: 0.3333 - val_accuracy: 0.8838\n",
      "Epoch 51/128\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2225 - accuracy: 0.9174 - val_loss: 0.3396 - val_accuracy: 0.8839\n",
      "Epoch 52/128\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2190 - accuracy: 0.9191 - val_loss: 0.3411 - val_accuracy: 0.8836\n",
      "Epoch 53/128\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2188 - accuracy: 0.9182 - val_loss: 0.3412 - val_accuracy: 0.8800\n",
      "Epoch 54/128\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2165 - accuracy: 0.9187 - val_loss: 0.3539 - val_accuracy: 0.8814\n",
      "Epoch 55/128\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2141 - accuracy: 0.9205 - val_loss: 0.3417 - val_accuracy: 0.8826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/128\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2113 - accuracy: 0.9223 - val_loss: 0.3368 - val_accuracy: 0.8836\n",
      "Epoch 57/128\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2093 - accuracy: 0.9225 - val_loss: 0.3348 - val_accuracy: 0.8836\n",
      "Epoch 58/128\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.2086 - accuracy: 0.9217 - val_loss: 0.3371 - val_accuracy: 0.8827\n",
      "Epoch 59/128\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.2068 - accuracy: 0.9227 - val_loss: 0.3340 - val_accuracy: 0.8850\n",
      "Epoch 60/128\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2051 - accuracy: 0.9241 - val_loss: 0.3533 - val_accuracy: 0.8812\n",
      "Epoch 61/128\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2028 - accuracy: 0.9253 - val_loss: 0.3342 - val_accuracy: 0.8874\n",
      "Epoch 62/128\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2010 - accuracy: 0.9249 - val_loss: 0.3334 - val_accuracy: 0.8860\n",
      "Epoch 63/128\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.1989 - accuracy: 0.9251 - val_loss: 0.3554 - val_accuracy: 0.8839\n",
      "Epoch 64/128\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.1964 - accuracy: 0.9266 - val_loss: 0.3471 - val_accuracy: 0.8874\n",
      "Epoch 65/128\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.1959 - accuracy: 0.9273 - val_loss: 0.3337 - val_accuracy: 0.8875\n",
      "Epoch 66/128\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1943 - accuracy: 0.9281 - val_loss: 0.3435 - val_accuracy: 0.8839\n",
      "Epoch 67/128\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.1918 - accuracy: 0.9283 - val_loss: 0.3431 - val_accuracy: 0.8850\n",
      "Epoch 68/128\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.1908 - accuracy: 0.9285 - val_loss: 0.3432 - val_accuracy: 0.8865\n",
      "Epoch 69/128\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1880 - accuracy: 0.9292 - val_loss: 0.3564 - val_accuracy: 0.8855\n",
      "Epoch 70/128\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.1865 - accuracy: 0.9312 - val_loss: 0.3541 - val_accuracy: 0.8851\n",
      "Epoch 71/128\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1855 - accuracy: 0.9317 - val_loss: 0.3488 - val_accuracy: 0.8888\n",
      "Epoch 72/128\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.1838 - accuracy: 0.9316 - val_loss: 0.3569 - val_accuracy: 0.8856\n",
      "Epoch 73/128\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1823 - accuracy: 0.9327 - val_loss: 0.3556 - val_accuracy: 0.8853\n",
      "Epoch 74/128\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.1814 - accuracy: 0.9328 - val_loss: 0.3541 - val_accuracy: 0.8902\n",
      "Epoch 75/128\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1800 - accuracy: 0.9320 - val_loss: 0.3549 - val_accuracy: 0.8842\n",
      "Epoch 76/128\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1770 - accuracy: 0.9345 - val_loss: 0.3604 - val_accuracy: 0.8856\n",
      "Epoch 77/128\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1773 - accuracy: 0.9348 - val_loss: 0.3525 - val_accuracy: 0.8882\n",
      "Epoch 78/128\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1750 - accuracy: 0.9353 - val_loss: 0.3471 - val_accuracy: 0.8862\n",
      "Epoch 79/128\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1739 - accuracy: 0.9353 - val_loss: 0.3563 - val_accuracy: 0.8852\n",
      "Epoch 80/128\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1722 - accuracy: 0.9362 - val_loss: 0.3551 - val_accuracy: 0.8879\n",
      "Epoch 81/128\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1703 - accuracy: 0.9369 - val_loss: 0.3553 - val_accuracy: 0.8898\n",
      "Epoch 82/128\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1692 - accuracy: 0.9361 - val_loss: 0.3796 - val_accuracy: 0.8842\n",
      "Epoch 83/128\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1680 - accuracy: 0.9379 - val_loss: 0.3743 - val_accuracy: 0.8845\n",
      "Epoch 84/128\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1676 - accuracy: 0.9375 - val_loss: 0.3693 - val_accuracy: 0.8874\n",
      "Epoch 85/128\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1659 - accuracy: 0.9375 - val_loss: 0.3611 - val_accuracy: 0.8892\n",
      "Epoch 86/128\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.1658 - accuracy: 0.9380 - val_loss: 0.3703 - val_accuracy: 0.8857\n",
      "Epoch 87/128\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1633 - accuracy: 0.9392 - val_loss: 0.3613 - val_accuracy: 0.8912\n",
      "Epoch 88/128\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1618 - accuracy: 0.9397 - val_loss: 0.3693 - val_accuracy: 0.8870\n",
      "Epoch 89/128\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1599 - accuracy: 0.9412 - val_loss: 0.3838 - val_accuracy: 0.8817\n",
      "Epoch 90/128\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1596 - accuracy: 0.9409 - val_loss: 0.3716 - val_accuracy: 0.8879\n",
      "Epoch 91/128\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.1570 - accuracy: 0.9418 - val_loss: 0.3758 - val_accuracy: 0.8882\n",
      "Epoch 92/128\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1569 - accuracy: 0.9415 - val_loss: 0.3717 - val_accuracy: 0.8837\n",
      "Epoch 93/128\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1551 - accuracy: 0.9421 - val_loss: 0.3714 - val_accuracy: 0.8862\n",
      "Epoch 94/128\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.1539 - accuracy: 0.9426 - val_loss: 0.3686 - val_accuracy: 0.8907\n",
      "Epoch 95/128\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1529 - accuracy: 0.9430 - val_loss: 0.3672 - val_accuracy: 0.8886\n",
      "Epoch 96/128\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1515 - accuracy: 0.9434 - val_loss: 0.3758 - val_accuracy: 0.8901\n",
      "Epoch 97/128\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1493 - accuracy: 0.9442 - val_loss: 0.3786 - val_accuracy: 0.8902\n",
      "Epoch 98/128\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1485 - accuracy: 0.9453 - val_loss: 0.3810 - val_accuracy: 0.8865\n",
      "Epoch 99/128\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1484 - accuracy: 0.9448 - val_loss: 0.3939 - val_accuracy: 0.8844\n",
      "Epoch 100/128\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1469 - accuracy: 0.9449 - val_loss: 0.3725 - val_accuracy: 0.8909\n",
      "Epoch 101/128\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1456 - accuracy: 0.9453 - val_loss: 0.3818 - val_accuracy: 0.8894\n",
      "Epoch 102/128\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1452 - accuracy: 0.9473 - val_loss: 0.3964 - val_accuracy: 0.8919\n",
      "Epoch 103/128\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1432 - accuracy: 0.9471 - val_loss: 0.3909 - val_accuracy: 0.8854\n",
      "Epoch 104/128\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1429 - accuracy: 0.9473 - val_loss: 0.4000 - val_accuracy: 0.8870\n",
      "Epoch 105/128\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1419 - accuracy: 0.9470 - val_loss: 0.4286 - val_accuracy: 0.8772\n",
      "Epoch 106/128\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1393 - accuracy: 0.9482 - val_loss: 0.4019 - val_accuracy: 0.8875\n",
      "Epoch 107/128\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1384 - accuracy: 0.9490 - val_loss: 0.3930 - val_accuracy: 0.8893\n",
      "Epoch 108/128\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1369 - accuracy: 0.9494 - val_loss: 0.3898 - val_accuracy: 0.8911\n",
      "Epoch 109/128\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1364 - accuracy: 0.9492 - val_loss: 0.4129 - val_accuracy: 0.8810\n",
      "Epoch 110/128\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.1364 - accuracy: 0.9494 - val_loss: 0.4075 - val_accuracy: 0.8892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/128\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.1345 - accuracy: 0.9499 - val_loss: 0.3937 - val_accuracy: 0.8899\n",
      "Epoch 112/128\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1343 - accuracy: 0.9503 - val_loss: 0.4062 - val_accuracy: 0.8880\n",
      "Epoch 113/128\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.1331 - accuracy: 0.9510 - val_loss: 0.4085 - val_accuracy: 0.8902\n",
      "Epoch 114/128\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1315 - accuracy: 0.9511 - val_loss: 0.4287 - val_accuracy: 0.8851\n",
      "Epoch 115/128\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1316 - accuracy: 0.9517 - val_loss: 0.3966 - val_accuracy: 0.8919\n",
      "Epoch 116/128\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1305 - accuracy: 0.9513 - val_loss: 0.4322 - val_accuracy: 0.8840\n",
      "Epoch 117/128\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1286 - accuracy: 0.9518 - val_loss: 0.4085 - val_accuracy: 0.8896\n",
      "Epoch 118/128\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1271 - accuracy: 0.9531 - val_loss: 0.4083 - val_accuracy: 0.8920\n",
      "Epoch 119/128\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.1261 - accuracy: 0.9536 - val_loss: 0.4253 - val_accuracy: 0.8863\n",
      "Epoch 120/128\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.1263 - accuracy: 0.9531 - val_loss: 0.4296 - val_accuracy: 0.8892\n",
      "Epoch 121/128\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1250 - accuracy: 0.9537 - val_loss: 0.4221 - val_accuracy: 0.8873\n",
      "Epoch 122/128\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.1227 - accuracy: 0.9552 - val_loss: 0.4124 - val_accuracy: 0.8886\n",
      "Epoch 123/128\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1221 - accuracy: 0.9552 - val_loss: 0.4220 - val_accuracy: 0.8893\n",
      "Epoch 124/128\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1218 - accuracy: 0.9555 - val_loss: 0.4591 - val_accuracy: 0.8835\n",
      "Epoch 125/128\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.1217 - accuracy: 0.9555 - val_loss: 0.4259 - val_accuracy: 0.8895\n",
      "Epoch 126/128\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1196 - accuracy: 0.9557 - val_loss: 0.4363 - val_accuracy: 0.8877\n",
      "Epoch 127/128\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.1190 - accuracy: 0.9564 - val_loss: 0.4418 - val_accuracy: 0.8842\n",
      "Epoch 128/128\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1173 - accuracy: 0.9569 - val_loss: 0.4227 - val_accuracy: 0.8908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1da853e0588>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics =['accuracy'])\n",
    "model.fit(X_train,\n",
    "           y_train,\n",
    "          epochs = 128,\n",
    "          validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.42270810841917994, 0.8907999992370605]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test,verbose =0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar matriz dde confusoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = model.predict(X_test)\n",
    "previsoes = (previsoes > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[884   2   8  14   3   0  82   0   7   0]\n",
      " [  5 978   1  11   1   0   2   0   1   1]\n",
      " [ 48   0 806  19  79   0  48   0   0   0]\n",
      " [ 38  10   7 896  26   0  17   0   6   0]\n",
      " [ 21   3  84  30 818   0  44   0   0   0]\n",
      " [  1   0   0   1   0 948   0  27   1  22]\n",
      " [158   1  68  25  69   0 669   0  10   0]\n",
      " [  0   0   0   0   0  14   0 968   0  18]\n",
      " [ 12   1   1   4   3   1   6   7 965   0]\n",
      " [  0   1   0   0   0   8   1  33   0 957]]\n"
     ]
    }
   ],
   "source": [
    "y_test_matrix = [np.argmax(t) for t in y_test]\n",
    "y_previsao_matrix = [np.argmax(t) for t in previsoes]\n",
    "confusao = confusion_matrix(y_test_matrix,y_previsao_matrix)\n",
    "print(confusao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
